{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0813 Chen Summary.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "12FcHULWW2uQoGk_45K_AFdm2NZRY-yaR",
      "authorship_tag": "ABX9TyPPEUKSEh2NUCWhtoLrTyuL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cc4351/teamtracking/blob/Chen/0813_Chen_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spR_l5WV7AC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# table of content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYWrCJ-77I9r",
        "colab_type": "text"
      },
      "source": [
        "# RNN pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP1C3RAO7Tff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "import statistics\n",
        "import math\n",
        "from time import time\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "import plotly.express as px\n",
        "import queue\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCvGv0Wb7Qol",
        "colab_type": "text"
      },
      "source": [
        "## data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_v8kAM-7lFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "70be837f-4561-4b88-c203-37109b22ca94"
      },
      "source": [
        "# replace the root path\n",
        "# switching into the folder containing all the data and listdir\n",
        "%cd '/content/drive/My Drive/Colab Notebooks/Molecule/data/RNN_train' \n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Molecule/data/RNN_train\n",
            "model.png\t     receptorInfoLabeled.mat\tsamplePBnnMatrix.pkl\n",
            "receptorInfoAll.mat  receptorInfoLabeledPB.mat\ttracksFinal.mat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97tQ09L97t9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rootPath = r'.'\n",
        "tracks = loadmat(os.path.join(rootPath, 'receptorInfoLabeledPB'))['receptorInfoLabeledPB']\n",
        "labeledTracks = tracks['receptorTraj'][0,0]\n",
        "movieInfo = np.transpose(labeledTracks, (2, 0, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LntThsEY7619",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize the first track\n",
        "track1 = labeledTracks[0]\n",
        "df = pd.DataFrame(track1.transpose(), columns=['x', 'y'])\n",
        "px.scatter_3d(df, x='x', y='y', z=df.index, size=np.ones(df.shape[0])*.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cffEZ3wl79BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ref: https://stackoverflow.com/a/16193445\n",
        "# get num_nn number of nearest neighbors for each particle\n",
        "def nnMatrix(num_neighbors, particles):\n",
        "    particleInfo = [np.asarray(frame) for frame in particles]\n",
        "    loc_dic = defaultdict(dict)\n",
        "    idx = 0\n",
        "    for item in enumerate(particleInfo[:-1]):\n",
        "        idx = item[0]\n",
        "        frame = item[1]\n",
        "        nextFrame = particleInfo[idx+1]\n",
        "        for ptr in enumerate(frame):\n",
        "            pt = ptr[1]\n",
        "            if any(np.isnan(pt)) == True:\n",
        "                continue\n",
        "            dist = [np.sum((pt-p2)**2) for p2 in nextFrame]\n",
        "            tmp_dic = {it[1]:it[0] for it in enumerate(dist)}\n",
        "            # ret = heapq.nsmallest(num_neighbors, dist)\n",
        "            dist = np.asarray(dist)\n",
        "            i = np.argsort(dist)\n",
        "            ret = i[np.isfinite(dist[i])][:num_neighbors]\n",
        "            # numPadding = num_neighbors - len(ret)+1\n",
        "            ret = np.append(ret, [-1])\n",
        "            loc_dic[idx][ptr[0]] = {'x': pt[0], 'y': pt[1], 'nbrs': ret}\n",
        "    # add x-y coordinate for last frame\n",
        "    for ptr in enumerate(particleInfo[-1]):\n",
        "        if np.isfinite(ptr[1][0]):\n",
        "            loc_dic[idx+1][ptr[0]] = {'x':ptr[1][0], 'y':ptr[1][1], 'nbrs':[-1]}\n",
        "    return list(loc_dic.values())\n",
        "\n",
        "# get all possible hypotheses in padded format\n",
        "def getHypTracks(nnMatrices, startFrame, startIdx, numNN, forwardProp = 3):\n",
        "    numTrack = int((numNN**(forwardProp+1)-1)/(numNN-1))\n",
        "    numFrames = len(nnMatrices)\n",
        "    fakeDict = {'x':-1, 'y':-1, 'nbrs':[]}\n",
        "    padding = [-1, -1]\n",
        "    def helper(frame, idx, depth):\n",
        "        if frame >= numFrames or depth > forwardProp or (idx > -1 and idx not in nnMatrices[frame]):\n",
        "            return []\n",
        "        if idx == -1:\n",
        "            root = fakeDict\n",
        "        else:\n",
        "            root = nnMatrices[frame][idx]\n",
        "        xy = [root['x'], root['y']]\n",
        "        results = [xy+path for kid in root['nbrs'] if kid != None for path in helper(frame+1, kid, depth+1)] or [xy]\n",
        "        return results\n",
        "    results = []\n",
        "    for track in helper(startFrame, startIdx, 0):\n",
        "        endPadding = forwardProp + 1 - int(len(track)/2)\n",
        "        tmp = padding + track + padding*(1+endPadding)\n",
        "        tmp = np.asarray(tmp).reshape(-1, 2)\n",
        "        results.append(tmp)\n",
        "    if len(results) == 0:\n",
        "        print(f\"no {startIdx} in {startFrame}\")\n",
        "        return results\n",
        "    fakeTrack = np.asarray([padding for i in range(forwardProp+3)])\n",
        "    for _ in range(numTrack - len(results)):\n",
        "        results.append(fakeTrack)\n",
        "    return results\n",
        "    \n",
        "# get ground truth labels\n",
        "def getTruth(trackSeg, nnSeg, idx, frame, numNN):\n",
        "    # if the pt doesn't exist in current frame\n",
        "    if np.isfinite(trackSeg[0][0]) == False:\n",
        "        print(f\"idx not exist in frame {frame}\")\n",
        "        return \n",
        "    # if the pt exist in current frame but not in the next frame\n",
        "    elif len(trackSeg) == 1 or np.isfinite(trackSeg[0][1]) == False:\n",
        "        print(f\"idx not exist in frame {frame+1}\")\n",
        "        return ([0]*(numNN)+[1], [0, 1])\n",
        "    # pt exist in both frames\n",
        "    else:\n",
        "        # double checking if this pt exist in this frame\n",
        "        if idx not in nnSeg:\n",
        "            print(f\"idx {idx} not in frame {frame} --nnMatrices\")\n",
        "            return\n",
        "        # the idx in next frame would be the same with this frame\n",
        "        hot = idx\n",
        "        # print(\"hot: \", hot)\n",
        "        nbrs = nnSeg[idx]['nbrs']\n",
        "        # print(\"nbrs: \", nbrs)\n",
        "        # find the index of the matching particle in the nbrs list\n",
        "        loc = np.where(nbrs ==hot)[0]\n",
        "        if len(loc) == 0 or loc[0] == -1:\n",
        "            print(f\"current nbrs are {nbrs}: idx {idx} not found in nbrs\")\n",
        "            loc = -1\n",
        "        else:\n",
        "            loc = loc[0]\n",
        "        encoding = [0]*(numNN+1)\n",
        "        encoding[loc] = 1\n",
        "        existence = [1, 0]\n",
        "        return (encoding, existence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIXVyJ-p5C27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nnMatrices = nnMatrix(3, movieInfo)\n",
        "nnMatrices = pickle.load(open('./samplePBnnMatrix.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzXKr30iSnwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuYc06J5HH00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "68fd1217-8462-4f14-8677-c90a8e9385db"
      },
      "source": [
        "d = 2\n",
        "numNN = 3\n",
        "batchNumTrack = int((numNN**(d+1)-1)/(numNN-1))\n",
        "print(\"batchNumTrack: \", batchNumTrack)\n",
        "allX = []\n",
        "allAsgn = []\n",
        "allExt = []\n",
        "numTracks = len(labeledTracks)\n",
        "numFrames = len(nnMatrices)-1\n",
        "for idx in range(numTracks):\n",
        "    for t in range(numFrames):\n",
        "        if idx not in nnMatrices[t]:\n",
        "            break\n",
        "        tracks = getHypTracks(nnMatrices, t, idx, numNN, d)\n",
        "        assert len(tracks) == batchNumTrack or len(tracks) == 0\n",
        "        if len(tracks) == 0:\n",
        "            print(\"oopsie\")\n",
        "            break\n",
        "        allX.append(tracks)\n",
        "        truth, existence = getTruth(labeledTracks[idx,:,t:t+2].T, nnMatrices[t], idx, t, numNN)\n",
        "        assert len(truth) == numNN + 1\n",
        "        assert sum(existence) == 1\n",
        "        allAsgn.append(truth)\n",
        "        allExt.append(existence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batchNumTrack:  13\n",
            "current nbrs are [16 15 22 -1]: idx 0 not found in nbrs\n",
            "current nbrs are [27  3 12 -1]: idx 1 not found in nbrs\n",
            "current nbrs are [20 10 15 -1]: idx 2 not found in nbrs\n",
            "current nbrs are [21 25  7 -1]: idx 3 not found in nbrs\n",
            "current nbrs are [36 25 30 -1]: idx 4 not found in nbrs\n",
            "current nbrs are [11  7 -1]: idx 5 not found in nbrs\n",
            "current nbrs are [ 7 19 21 -1]: idx 6 not found in nbrs\n",
            "current nbrs are [32  9 33 -1]: idx 8 not found in nbrs\n",
            "current nbrs are [21  6 19 -1]: idx 9 not found in nbrs\n",
            "current nbrs are [25  0  3 -1]: idx 10 not found in nbrs\n",
            "current nbrs are [ 7 -1]: idx 11 not found in nbrs\n",
            "current nbrs are [ 7  3 21 -1]: idx 12 not found in nbrs\n",
            "current nbrs are [28 15 29 -1]: idx 13 not found in nbrs\n",
            "current nbrs are [ 9  6 21 -1]: idx 14 not found in nbrs\n",
            "current nbrs are [ 5 21  3 -1]: idx 15 not found in nbrs\n",
            "current nbrs are [21  3 15 -1]: idx 16 not found in nbrs\n",
            "current nbrs are [ 8  9 33 -1]: idx 17 not found in nbrs\n",
            "current nbrs are [10  0 29 -1]: idx 18 not found in nbrs\n",
            "current nbrs are [ 7 21 12 -1]: idx 19 not found in nbrs\n",
            "current nbrs are [19  7 29 -1]: idx 20 not found in nbrs\n",
            "current nbrs are [ 7 25  5 -1]: idx 21 not found in nbrs\n",
            "current nbrs are [ 5 11  7 -1]: idx 22 not found in nbrs\n",
            "current nbrs are [27  1  3 -1]: idx 23 not found in nbrs\n",
            "current nbrs are [18 28 22 -1]: idx 24 not found in nbrs\n",
            "current nbrs are [ 7 22  5 -1]: idx 25 not found in nbrs\n",
            "current nbrs are [21 12  6 -1]: idx 26 not found in nbrs\n",
            "current nbrs are [12  3  7 -1]: idx 27 not found in nbrs\n",
            "current nbrs are [15  5 18 -1]: idx 28 not found in nbrs\n",
            "current nbrs are [10  0 19 -1]: idx 29 not found in nbrs\n",
            "current nbrs are [ 3 27  1 -1]: idx 30 not found in nbrs\n",
            "current nbrs are [24 18 13 -1]: idx 31 not found in nbrs\n",
            "current nbrs are [ 9  6 21 -1]: idx 32 not found in nbrs\n",
            "current nbrs are [ 6 21  9 -1]: idx 33 not found in nbrs\n",
            "current nbrs are [36 25  7 -1]: idx 34 not found in nbrs\n",
            "current nbrs are [19 27  1 -1]: idx 35 not found in nbrs\n",
            "current nbrs are [30  3 25 -1]: idx 36 not found in nbrs\n",
            "current nbrs are [26 23 21 -1]: idx 37 not found in nbrs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtOQdKjo8S2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4196f52-4bfd-4d42-feaf-d2f30a6b8f54"
      },
      "source": [
        "# unit test before training\n",
        "# the index thingy need to be randomized/sorted in the u-track way\n",
        "\n",
        "len(allX), len(allAsgn), len(allExt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50840, 50840, 50840)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8m19hbZKZpI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a4b00cb-eacb-4620-9112-85e7127fa2e9"
      },
      "source": [
        "# numNN = 3\n",
        "# d = 2\n",
        "# t = 4000\n",
        "# idx = 7\n",
        "# # nnMatrices = nnMatrix(3, movieInfo)\n",
        "# tracks = getHypTracks(nnMatrices, t, idx, numNN, d)\n",
        "# # remember to check if t is the last frame\n",
        "# truth, existence = getTruth(labeledTracks[idx,:,t:t+2].T, nnMatrices[t], idx, t, numNN)\n",
        "# truth, existence\n",
        "import random\n",
        "\n",
        "c = list(zip(allX, allAsgn, allExt))\n",
        "random.shuffle(c)\n",
        "allX, allAsgn, allExt = zip(*c)\n",
        "allX = list(allX)\n",
        "allAsgn = list(allAsgn)\n",
        "allExt = list(allExt)\n",
        "\n",
        "allAsgn[0], allExt[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 0, 0, 0], [1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj6n6zBFOzwC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "outputId": "c9cb5d3d-61d7-407f-8e0a-928599d57f72"
      },
      "source": [
        "allX[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 5.94978352, 12.4493243 ],\n",
              "        [ 5.93745409, 12.49473248],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 5.94978352, 12.4493243 ],\n",
              "        [ 6.30155956, 15.9512826 ],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 5.94978352, 12.4493243 ],\n",
              "        [ 2.77884018,  9.43847762],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 5.94978352, 12.4493243 ],\n",
              "        [-1.        , -1.        ],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 6.35341208, 15.98680597],\n",
              "        [ 6.30155956, 15.9512826 ],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 6.35341208, 15.98680597],\n",
              "        [ 3.78819601, 16.83269877],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 6.35341208, 15.98680597],\n",
              "        [ 4.99709469, 18.54476273],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 6.35341208, 15.98680597],\n",
              "        [-1.        , -1.        ],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 2.6566802 ,  9.42371959],\n",
              "        [ 2.77884018,  9.43847762],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 2.6566802 ,  9.42371959],\n",
              "        [ 0.82867606,  8.97883348],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 2.6566802 ,  9.42371959],\n",
              "        [ 3.68754183,  5.90079285],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [ 2.6566802 ,  9.42371959],\n",
              "        [-1.        , -1.        ],\n",
              "        [-1.        , -1.        ]]), array([[-1.        , -1.        ],\n",
              "        [ 6.01981178, 12.47991293],\n",
              "        [-1.        , -1.        ],\n",
              "        [-1.        , -1.        ],\n",
              "        [-1.        , -1.        ]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri9jAGT2FPix",
        "colab_type": "text"
      },
      "source": [
        "## model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf06YLsUFtSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ref: https://keras.io/api/models/model_training_apis/\n",
        "# model itself\n",
        "class rnnModel(keras.Model):\n",
        "    def __init__(self, numNN, t, d, numFilter = 12, k=64, numDim = 2, dropout = 0.25, t_init = 0, batch_size = None):\n",
        "        super(rnnModel, self).__init__()\n",
        "        dt = t + d + 1 - t_init \n",
        "        rate = dropout\n",
        "        # (numNN+1)**d := total number of hypotheses to consider\n",
        "        # dt := length of each track\n",
        "        # numDim := length of each datapoint \n",
        "        inputDimOne = int((numNN**(d+1)-1)/(numNN-1))\n",
        "        input_size = (inputDimOne, dt, numDim)\n",
        "        ins = keras.Input(shape=input_size, batch_size=batch_size)\n",
        "        x = layers.Conv1D(numFilter, 3 , activation='relu',input_shape=input_size[2:])(ins)\n",
        "        x = tf.reshape(x, x.shape[1:])\n",
        "        x = layers.Bidirectional(layers.LSTM(k, return_sequences=True))(x)\n",
        "        x = layers.Bidirectional(layers.LSTM(k, return_sequences=True))(x)\n",
        "        x = layers.Bidirectional(layers.LSTM(k))(x)\n",
        "        x = layers.Dense(k, activation='relu')(x)\n",
        "        x = layers.GaussianDropout(rate)(x)\n",
        "        x = layers.Dense(1, activation='relu')(x)\n",
        "        x = layers.GaussianDropout(rate)(x)\n",
        "        x = tf.reshape(x, [1, x.shape[0], x.shape[1]])\n",
        "        x = layers.MaxPool1D(pool_size=(numNN+1)**(d-1), name=\"pool1\", padding=\"same\")(x)\n",
        "        x = tf.reshape(x, [x.shape[0], x.shape[1]])\n",
        "        z = layers.Dense(k, input_shape =(numNN+1,1), activation='relu')(x)\n",
        "        z = layers.GaussianDropout(rate)(z)\n",
        "        z = layers.Dense(k, activation='relu')(z)\n",
        "        z = layers.GaussianDropout(rate)(z)\n",
        "        z = layers.Dense(numNN+1, activation='relu')(z)\n",
        "        f1_output = layers.Softmax(name=\"assignment\")(z)\n",
        "\n",
        "        y = layers.Dense(k, input_shape =(numNN+1,1), activation='relu')(x)\n",
        "        y = layers.GaussianDropout(rate)(y)\n",
        "        y = layers.Dense(k, activation='relu')(y)\n",
        "        y = layers.GaussianDropout(rate)(y)\n",
        "        y = layers.Dense(2, activation='relu')(y)\n",
        "        f2_output = layers.Softmax(name=\"existence\")(y)\n",
        "\n",
        "        ensemble = keras.Model(inputs=ins, outputs=[f1_output, f2_output])\n",
        "\n",
        "        opt = keras.optimizers.Adam(\n",
        "            learning_rate=0.001,\n",
        "            beta_1=0.9,\n",
        "            beta_2=0.999,\n",
        "            epsilon=1e-07,\n",
        "            amsgrad=False,\n",
        "            name=\"Adam\",\n",
        "        )\n",
        "\n",
        "        losses = {\n",
        "            \"assignment\": \"categorical_crossentropy\",\n",
        "            \"existence\": \"categorical_crossentropy\",\n",
        "        }\n",
        "\n",
        "        lossWeights = {\"assignment\": 1.0, \"existence\": 1.0}\n",
        "        # keras.utils.plot_model(ensemble, show_shapes=True)\n",
        "        ensemble.compile(\n",
        "            optimizer=opt,\n",
        "            loss=losses,\n",
        "            metrics=['accuracy'],\n",
        "            loss_weights=lossWeights,\n",
        "            weighted_metrics=None,\n",
        "            run_eagerly=None,\n",
        "        )\n",
        "\n",
        "        self.model = ensemble\n",
        "    def call(self, tracks, batch_size = 1, training=False):\n",
        "        return self.model.predict(tf.constant(tracks), batch_size = batch_size)\n",
        "        \n",
        "    def train(self, tracks, labels, epochs = 10, batch_size = 1, callbacks=[], verbose = 1):\n",
        "        defaultCallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "        return self.model.fit(tf.constant(tracks), labels,\n",
        "                    epochs=epochs, batch_size=batch_size, callbacks=[defaultCallback],verbose=verbose)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC6jz5eKFWDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = 2\n",
        "numNN = 3\n",
        "sampleModel = rnnModel(numNN = numNN, t = 2, d = d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwH9jeSkrFpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "629c8d22-9e4d-4a9e-cb6a-1c1a172ffa74"
      },
      "source": [
        "# tfX = []\n",
        "# for X in allX:\n",
        "#     tfX.append(tf.constant(X))\n",
        "dumX = tf.constant(allX)\n",
        "asg = tf.constant(allAsgn)\n",
        "ext = tf.constant(allExt)\n",
        "dumX.shape, asg.shape, ext.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([50840, 13, 5, 2]),\n",
              " TensorShape([50840, 4]),\n",
              " TensorShape([50840, 2]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVsi1skTFzDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "e3a0df2c-0541-4354-909d-ce012705a6fa"
      },
      "source": [
        "history = sampleModel.train(dumX, [asg, ext])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50840/50840 [==============================] - 564s 11ms/step - loss: 0.0435 - assignment_loss: 0.0435 - existence_loss: 3.0893e-08 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "50840/50840 [==============================] - 543s 11ms/step - loss: 0.0353 - assignment_loss: 0.0353 - existence_loss: 2.8138e-11 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "50840/50840 [==============================] - 547s 11ms/step - loss: 0.0343 - assignment_loss: 0.0343 - existence_loss: 9.3792e-12 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "50840/50840 [==============================] - 577s 11ms/step - loss: 0.0333 - assignment_loss: 0.0333 - existence_loss: 3.2827e-11 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "50840/50840 [==============================] - 564s 11ms/step - loss: 0.0328 - assignment_loss: 0.0328 - existence_loss: 7.0344e-12 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "50840/50840 [==============================] - 575s 11ms/step - loss: 0.0322 - assignment_loss: 0.0322 - existence_loss: 7.0344e-12 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "50840/50840 [==============================] - 573s 11ms/step - loss: 0.0319 - assignment_loss: 0.0319 - existence_loss: 0.0000e+00 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "50840/50840 [==============================] - 570s 11ms/step - loss: 0.0325 - assignment_loss: 0.0325 - existence_loss: 0.0000e+00 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "50840/50840 [==============================] - 570s 11ms/step - loss: 0.0324 - assignment_loss: 0.0324 - existence_loss: 0.0000e+00 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "50840/50840 [==============================] - 631s 12ms/step - loss: 0.0318 - assignment_loss: 0.0318 - existence_loss: 0.0000e+00 - assignment_accuracy: 0.9959 - existence_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ1ge_SAGZh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TO-DO\n",
        "# 1. batch size\n",
        "# 2. lr_finder\n",
        "# 3. think about the track prcessing by 13 vs. by 1, \n",
        "#    and the negative effect of padding the input with [-1]*hypTrackLength (aka that's what I do rn)\n",
        "# 4. track maintenance"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}